{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import TFCamembertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a tensor of tokens_ids\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jplu/tf-camembert-base\", do_lower_case=True)\n",
    "sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tensor = tf.convert_to_tensor(tokens_ids)\n",
    "tensorTokensIds = tf.expand_dims(tensor, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model and Test Different Kinds of Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"jplu/tf-camembert-base\", do_lower_case=True)\n",
    "# sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "# tokens = tokenizer.tokenize(sentence)\n",
    "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# tensor = tf.convert_to_tensor(tokens_ids)\n",
    "# tensor = tf.expand_dims(tensor, 0)\n",
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Check BERT output\n",
    "\n",
    "# bertLayer = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "# bertLayer(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### generate a random tensor\n",
    "# tensor = tf.random.uniform(shape=[1, 32, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Check BERT output\n",
    "\n",
    "# bertLayer = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "# bertLayer(None, inputs_embeds=tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Test the Model\n",
    "\n",
    "# sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "# tokens = tokenizer.tokenize(sentence)\n",
    "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# tensor = tf.convert_to_tensor(tokens_ids)\n",
    "# tensor = tf.expand_dims(tensor, 0)\n",
    "\n",
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "# x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "# x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "# dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(bert_input, dense_out, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### generate a random tensor\n",
    "\n",
    "# inp = tf.random.uniform(shape=[1, 32, 768])\n",
    "# inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained CamemBERT and Get Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"jplu/tf-camembert-base\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "# tokens = tokenizer.tokenize(sentence)\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### convert list to tensor\n",
    "# tensor = tf.convert_to_tensor(tokens_ids)\n",
    "# tensor = tf.expand_dims(tensor, 0)\n",
    "# print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Get the Config File.\n",
    "# configFile = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(tensor)\n",
    "# print(type(output))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Word Embedding for Token Ids 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"jplu/tf-camembert-base\", do_lower_case=True)\n",
    "# sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "# tokens = tokenizer.tokenize(sentence)\n",
    "# print(tokens)\n",
    "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(tokens_ids)\n",
    "# ### convert list to tensor\n",
    "# tensor = tf.convert_to_tensor(tokens_ids)\n",
    "# tensor = tf.expand_dims(tensor, 0)\n",
    "# print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = tf.zeros(shape = (1, 32), dtype=tf.dtypes.int32)\n",
    "# print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Build Model and Load Weights\n",
    "\n",
    "# bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "# x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "# x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "# dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(bert_input, dense_out, name='model')\n",
    "\n",
    "# checkpointPath = \"../project_PunctuatorBERTTensorFlow2/Models/20200530_161559/cp-001.ckpt\"\n",
    "# model.load_weights(checkpointPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = tf.ones(shape = (1, 32), dtype=tf.dtypes.int32)\n",
    "# output = model(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT (Not Pre-Trained) and Get Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForMaskedLM(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(tensor)\n",
    "# # print(type(output))\n",
    "# # print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to Input inputs_embeds Instead of input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = TFBertForMaskedLM(configFile)\n",
    "# model = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### generate a random tensor\n",
    "# tensor = tf.random.uniform(shape=[1, 32, 768])\n",
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(None, inputs_embeds = tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Whether Word Embeddings Changes or Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether word_embeddings weights change between Pre-Trained and Fine-Tuned model.  \n",
    "They do change!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "# output = model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Model, Load Fine-Tuned Weights, Get the Output.\n",
    "\n",
    "# bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "# x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "# x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "# dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(bert_input, dense_out, name='model')\n",
    "\n",
    "# checkpointPath = \"../project_PunctuatorBERTTensorFlow2/Models/20200530_161559/cp-001.ckpt\"\n",
    "# model.load_weights(checkpointPath)\n",
    "\n",
    "# output = model(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word_embeddings Weigths From Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build model\n",
    "bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "model = tf.keras.Model(bert_input, dense_out, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.05740356  0.03015137  0.00317192 ...  0.10650635  0.01069641\n",
      "  -0.04116821]\n",
      " [ 0.00335693 -0.05578613 -0.00549698 ... -0.03201294 -0.00558853\n",
      "  -0.0276947 ]\n",
      " [-0.01337433  0.13696289  0.06750488 ...  0.00102425  0.07806396\n",
      "   0.0418396 ]\n",
      " ...\n",
      " [-0.03137207  0.11425781  0.07287598 ...  0.01905823  0.15014648\n",
      "  -0.14709473]\n",
      " [-0.12597656 -0.11895752 -0.08514404 ... -0.12359619  0.00794983\n",
      "  -0.19787598]\n",
      " [ 0.01429749 -0.02708435  0.00352287 ... -0.00690842  0.01070404\n",
      "  -0.00716782]], shape=(32005, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.trainable_variables[194][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build model\n",
    "bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "model = tf.keras.Model(bert_input, dense_out, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.05740356  0.03015137  0.00317192 ...  0.10650635  0.01069641\n",
      "  -0.04116821]\n",
      " [ 0.00335693 -0.05578613 -0.00549698 ... -0.03201294 -0.00558853\n",
      "  -0.0276947 ]\n",
      " [-0.01337433  0.13696289  0.06750488 ...  0.00102425  0.07806396\n",
      "   0.0418396 ]\n",
      " ...\n",
      " [-0.03137207  0.11425781  0.07287598 ...  0.01905823  0.15014648\n",
      "  -0.14709473]\n",
      " [-0.12597656 -0.11895752 -0.08514404 ... -0.12359619  0.00794983\n",
      "  -0.19787598]\n",
      " [ 0.01429749 -0.02708435  0.00352287 ... -0.00690842  0.01070404\n",
      "  -0.00716782]], shape=(32005, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.trainable_variables[194][0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word_embeddings Weigths From Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### build model\n",
    "# bert_input = tf.keras.Input(shape=(32), dtype='int32', name='bert_input')\n",
    "# x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(bert_input)[0]\n",
    "# x = tf.keras.layers.Reshape((32*32005,))(x)\n",
    "# dense_out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "# model = tf.keras.Model(bert_input, dense_out, name='model')\n",
    "\n",
    "# ### load checkpoints\n",
    "# checkpointPath = \"../project_PunctuatorBERTTensorFlow2/Models/20200530_161559/cp-001.ckpt\"\n",
    "# model.load_weights(checkpointPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print word_embeddings Weights\n",
    "# print(model.trainable_variables[194][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorQ = model.trainable_variables[194][0:]\n",
    "# tensorQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTrans",
   "language": "python",
   "name": "venvtrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
